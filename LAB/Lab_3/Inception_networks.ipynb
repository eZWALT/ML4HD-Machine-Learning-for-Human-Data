{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EjVJemTnxbl9"
   },
   "source": [
    "# Inception Neural Network\n",
    "\n",
    "Welcome to the fourth HDA laboratory! In this notebook, you will implement an advanced architecture: the **Inception-v4 network.** The architecture was proposed by [Google developers](https://arxiv.org/pdf/1602.07261.pdf) for image classification.\n",
    "\n",
    "**In this assignment, you will:**\n",
    "- Implement the basic building blocks of Inception-v4.\n",
    "- Put together these building blocks to implement and train a state-of-the-art neural network for image classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w3aPZ-WNCKtC"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZkhcgTWNCLep"
   },
   "outputs": [],
   "source": [
    "cd '/content/drive/MyDrive/MLHD_labs/Lab_3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nfd17NpHxbmM"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Input\n",
    "from tensorflow.keras.layers import Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D, Dropout, Concatenate\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import pydot\n",
    "import datetime\n",
    "from PIL import Image\n",
    "from IPython.display import SVG\n",
    "from load_utils import *\n",
    "from tensorflow.keras.initializers import glorot_uniform\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import scipy.misc\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.metrics import precision_recall_fscore_support, roc_curve, auc, accuracy_score, precision_recall_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cgcShtEIxbmO"
   },
   "source": [
    "# Dataset\n",
    "For this lab, you will use the [**PatchCamelyon** dataset](https://github.com/basveeling/pcam). It consists of 327.680 color images (96 x 96px) extracted from histopathologic scans of lymph node sections. Each image is annotated with a binary label indicating the presence of metastatic tissue.\n",
    "If the label is `1` it means that the center 32x32px region of a patch contains at least one pixel of tumor tissue. Tumor tissue in the outer region of the patch does not influence the label.\n",
    "\n",
    "In this notebook, you will use a smaller version of the dataset that consists of 6,000 images. Feel free to download the entire dataset to experiment with it (e.g., if you train the network with more examples, the performance of the designed classifier should increase).\n",
    "\n",
    "The function `load_data()` defined in `load_utils.py`, loads the smaller dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EhswQmwYxbmO"
   },
   "outputs": [],
   "source": [
    "load_data_dir = '../Datasets/Lab_3/'\n",
    "(x_train, y_train, meta_train), (x_test, y_test, meta_test) = load_data(load_data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HXWQMu8rxbmP"
   },
   "outputs": [],
   "source": [
    "print('TRAIN SET, images: {}'.format(x_train.shape))\n",
    "print('TRAIN SET, labels: {}'.format(y_train.shape))\n",
    "train_length = y_train.shape[0]\n",
    "\n",
    "print('TEST SET, images: {}'.format(x_test.shape))\n",
    "print('TEST SET, labels: {}'.format(y_test.shape))\n",
    "test_length = y_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v-l-4f4qxbmQ"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=[20,10])\n",
    "plt.subplot(1, 10, 1)\n",
    "\n",
    "for i in range(10):\n",
    "    plt.subplot(1, 10, i+1)\n",
    "    image = x_train[i, :, :, :]\n",
    "    plt.imshow(image)\n",
    "    label = y_train[i]\n",
    "    plt.title('class '+ str(label))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AOnyVjSUxbml"
   },
   "source": [
    "To train the models we will implement below on the image dataset, we use [ImageDataGenerator](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator) that generates batches of tensor image data. This class is useful when using image datasets as it allows applying real-time data augmentation. For the test generator we only apply normalization without data augmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HbHBMxhFxbml"
   },
   "outputs": [],
   "source": [
    "datagen_train = ImageDataGenerator(preprocessing_function=lambda x: x/255.,\n",
    "                             width_shift_range=4,  # randomly shift images horizontally\n",
    "                             height_shift_range=4,  # randomly shift images vertically\n",
    "                             horizontal_flip=True,  # randomly flip images\n",
    "                             vertical_flip=True)  # randomly flip images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A_jItT8Lxbmm"
   },
   "outputs": [],
   "source": [
    "datagen_test = ImageDataGenerator(preprocessing_function=lambda x: x/255.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "COswZGT6xbmn"
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_steps = int(np.ceil(train_length/batch_size))\n",
    "test_steps = int(np.ceil(test_length/batch_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gZbSbPQnCHzG"
   },
   "source": [
    "# Inception network\n",
    "\n",
    "In a pure Inception network, there are two different block types: the **inception block** and the **reduction block**.\n",
    "\n",
    "Inception-v4 is composed of 3 inception blocks, 2 reduction ones and an initial stem block.\n",
    "\n",
    "<img src=\"https://drive.google.com/uc?export=view&id=13ERbjo3D_J7SuLGDU5iXSlSilldD1xWT\" style=\"width:800px;\">\n",
    "<caption><center>  <br> </center></caption>\n",
    "\n",
    "**Note**: for the last activation we will use ``sigmoid`` with one output neuron (binary classification task)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T7yC5Y6Vwrnc"
   },
   "source": [
    "## 1 - Inception-v4 blocks\n",
    "### 1.1 - Convolutional and batch normalization helper function\n",
    "First of all, here below is implemented the ``conv2d_bn`` helper function that you will use in all the blocks of the Inception v4 network.\n",
    "\n",
    "Use the following structure:\n",
    "- CONV2D with $F$ filters of shape ($h$, $w$), stride of ($s_1$, $s_2$).\n",
    "- BatchNorm, normalizing the 'channels' axis.  \n",
    "- ReLU activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0oXK7-ghCHzH"
   },
   "outputs": [],
   "source": [
    "# FUNCTION: conv2d_bn block\n",
    "\n",
    "def conv2d_bn(X_input, filters, kernel_size, strides, padding='same', activation=None,\n",
    "              name=None):\n",
    "    \"\"\"\n",
    "    Implementation of a conv block as defined above\n",
    "\n",
    "    Arguments:\n",
    "    X_input -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
    "    filters -- integer, defining the number of filters in the CONV layer\n",
    "    kernel_size -- (f1, f2) tuple of integers, specifying the shape of the CONV kernel\n",
    "    s -- integer, specifying the stride to be used\n",
    "    padding -- padding approach to be used\n",
    "    name -- name for the layers\n",
    "\n",
    "    Returns:\n",
    "    X -- output of the conv2d_bn block, tensor of shape (n_H, n_W, n_C)\n",
    "    \"\"\"\n",
    "\n",
    "    # defining name basis\n",
    "    conv_name_base = 'conv_'\n",
    "    bn_name_base = 'bn_'\n",
    "\n",
    "    X = Conv2D(filters = filters, kernel_size = kernel_size, strides = strides,\n",
    "               padding = padding, name = conv_name_base + name,\n",
    "               kernel_initializer = glorot_uniform(seed=0))(X_input)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + name)(X)\n",
    "    if activation is not None:\n",
    "        X = Activation(activation)(X)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QV4tqiMZCHzH"
   },
   "source": [
    "### 1.2 - The stem block\n",
    "\n",
    "The stem block is designed as follows:\n",
    "\n",
    "<img src=\"https://drive.google.com/uc?export=view&id=19lyJj1qlee1uIjv1Hafb7DyjWRYvCN7a\" style=\"width:70%\">\n",
    "<caption><center> Stem block. </center></caption>\n",
    "\n",
    "Implement below all the steps by taking advantage of the above implemented ``conv2d_bn`` function for the blue rectangles.\n",
    "The values for the kernel sizes and the strides are specified in each block.\n",
    "\n",
    "*   Use stride 1x1 when it is not specified.\n",
    "*   Use padding \"valid\" when the letter **V** appears, otherwise use padding \"same\".\n",
    "\n",
    "As an exmaple, the first layer has the following parameters: 32 filters of shape (3, 3), stride of (2, 2), padding \"valid\" while the third one is composed of 64 filters of shape (3, 3), stride of (1, 1), padding \"same\".\n",
    "\n",
    "*  For the **Filter concat** layers (orange rectangles), use  [Concatenate](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Concatenate) and **concatenate along the 'channel' axis (axis=3)**.\n",
    "\n",
    "*  **Important suggestion**: add a **name** to each of the layers.\n",
    "*  Use 1 as the seed for the random initialization to reproduce the expected output.\n",
    "* The last conv block has ``stride = 2`` and the max pooling layer has ``kernel = (3, 3)``.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZiKm8lmXCHzH"
   },
   "outputs": [],
   "source": [
    "# FUNCTION: stem_block\n",
    "\n",
    "def stem_block(X_input):\n",
    "    \"\"\"\n",
    "    Implementation of the stem block as defined above\n",
    "\n",
    "    Arguments:\n",
    "    X_input -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
    "\n",
    "    Returns:\n",
    "    X -- output of the stem block, tensor of shape (n_H, n_W, n_C)\n",
    "    \"\"\"\n",
    "\n",
    "    ### START CODE HERE ###\n",
    "\n",
    "    # First conv\n",
    "    X = None\n",
    "\n",
    "    # Second conv\n",
    "    X = None\n",
    "\n",
    "    # Third conv\n",
    "    X = None\n",
    "\n",
    "    # First branch: max pooling\n",
    "    branch1 = None\n",
    "\n",
    "    # Second branch: conv\n",
    "    branch2 = None\n",
    "\n",
    "    # Concatenate (1) branch1 and branch2 along the channel axis\n",
    "    X = None\n",
    "\n",
    "    # First branch: 2 convs\n",
    "    branch1 = None\n",
    "\n",
    "    # Second branch: 4 convs\n",
    "    branch2 = None\n",
    "\n",
    "    # Concatenate (2) branch1 and branch2 along the channel axis\n",
    "    X = None\n",
    "\n",
    "    # First branch: conv\n",
    "    branch1 = None\n",
    "\n",
    "    # Second branch: max pooling\n",
    "    branch2 = None\n",
    "\n",
    "    # Concatenate (3) branch1 and branch2 along the channel axis\n",
    "    X = None\n",
    "\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VEljaRKFCHzH"
   },
   "outputs": [],
   "source": [
    "tf.random.set_seed(1)\n",
    "X_inp = tf.random.normal((4, 100, 100, 3), dtype=tf.dtypes.float32)\n",
    "\n",
    "X_out = stem_block(X_inp)\n",
    "print(\"shape output\" + str(X_out.shape))\n",
    "print(\"out = \" + str(X_out[:, 0, 0, 0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L3ek1DKYw3MI"
   },
   "source": [
    "Expected output:\n",
    "\n",
    "``shape output(4, 10, 10, 384)``\n",
    "\n",
    "``out = tf.Tensor([0.01137412 0.         0.01842478 0.        ], shape=(4,), dtype=float32)``\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OMe7PxvyCHzH"
   },
   "source": [
    "### 1.3 - The Inception-A block\n",
    "\n",
    "Implement below the Inception-A block as detailed in the figure:\n",
    "\n",
    "<img src=\"https://drive.google.com/uc?export=view&id=147HD5TVWw9qWywYh3DGl1Mv1uIQqoI07\" style=\"width:50%\">\n",
    "<caption><center> Inception-A block. </center></caption>\n",
    "\n",
    "#### Note\n",
    "\n",
    "- The average pooling has ``pool_size = (3, 3)`` and ``strides = (1, 1)``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CKdNzzQVCHzI"
   },
   "outputs": [],
   "source": [
    "# FUNCTION: Inception-A block\n",
    "\n",
    "def inception_a_block(X_input, base_name):\n",
    "    \"\"\"\n",
    "    Implementation of the Inception-A block\n",
    "\n",
    "    Arguments:\n",
    "    X_input -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
    "\n",
    "    Returns:\n",
    "    X -- output of the block, tensor of shape (n_H, n_W, n_C)\n",
    "    \"\"\"\n",
    "\n",
    "    ### START CODE HERE ###\n",
    "\n",
    "    # Branch 1\n",
    "    branch1 = None\n",
    "\n",
    "    # Branch 2\n",
    "    branch2 = None\n",
    "\n",
    "    # Branch 3\n",
    "    branch3 = None\n",
    "\n",
    "    # Branch 4\n",
    "    branch4 = None\n",
    "\n",
    "    # Concatenate branch1, branch2, branch3 and branch4 along the channel axis\n",
    "    X = None\n",
    "\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0o5cwh6_CHzI"
   },
   "outputs": [],
   "source": [
    "tf.random.set_seed(1)\n",
    "X_inp = tf.random.normal((4, 100, 100, 3), dtype=tf.dtypes.float32)\n",
    "\n",
    "X_out = inception_a_block(X_inp, 'a')\n",
    "print(\"shape output\" + str(X_out.shape))\n",
    "print(\"out = \" + str(X_out[:, 0, 0, 0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6JttROrZxAuL"
   },
   "source": [
    "Expected output:\n",
    "\n",
    "``shape output(4, 100, 100, 384)``\n",
    "\n",
    "``out = tf.Tensor([0.09909102 0.18648547 0.01800422 0.        ], shape=(4,), dtype=float32)``\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z34AAYffCHzI"
   },
   "source": [
    "### 1.4 - The Inception-B block\n",
    "\n",
    "Implement below the Inception-B block as detailed in the figure:\n",
    "\n",
    "<img src=\"https://drive.google.com/uc?export=view&id=1HO_HaRit39sEqzvZ9ETFp5TBQ36ApeZo\" style=\"width:50%\">\n",
    "<caption><center> Inception-B block. </center></caption>\n",
    "\n",
    "### Note\n",
    "- The average pooling has ``pool_size = (3, 3)`` and ``strides = (1, 1)``\n",
    "- In the **third** branch, the **last** convolutional layer has ``kernel_size = (7, 1)``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "grg4h-vRCHzI"
   },
   "outputs": [],
   "source": [
    "# FUNCTION: Inception-B block\n",
    "\n",
    "def inception_b_block(X_input, base_name):\n",
    "    \"\"\"\n",
    "    Implementation of the Inception-B block\n",
    "\n",
    "    Arguments:\n",
    "    X_input -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
    "\n",
    "    Returns:\n",
    "    X -- output of the block, tensor of shape (n_H, n_W, n_C)\n",
    "    \"\"\"\n",
    "\n",
    "    ### START CODE HERE ###\n",
    "\n",
    "    # Branch 1\n",
    "    branch1 = None\n",
    "\n",
    "    # Branch 2\n",
    "    branch2 = None\n",
    "\n",
    "    # Branch 3\n",
    "    branch3 = None\n",
    "\n",
    "    # Branch 4\n",
    "    branch4 = None\n",
    "\n",
    "    # Concatenate branch1, branch2, branch3 and branch4 along the channel axis\n",
    "    X = None\n",
    "\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zIbLENm0CHzI"
   },
   "outputs": [],
   "source": [
    "tf.random.set_seed(1)\n",
    "X_inp = tf.random.normal((4, 100, 100, 3), dtype=tf.dtypes.float32)\n",
    "\n",
    "X_out = inception_b_block(X_inp, 'b')\n",
    "print(\"shape output\" + str(X_out.shape))\n",
    "print(\"out = \" + str(X_out[:, 0, 0, 0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PsE9JyueCHzI"
   },
   "source": [
    "Expected output:\n",
    "\n",
    "``shape output(4, 100, 100, 1024)``\n",
    "\n",
    "``out = tf.Tensor([0.09139545 0.11461768 0.         0.03276341], shape=(4,), dtype=float32)\n",
    "``\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JwgtIm6VCHzI"
   },
   "source": [
    "### 1.5 - The Inception-C block\n",
    "\n",
    "Implement below the Inception-C block as detailed in the figure:\n",
    "\n",
    "<img src=\"https://drive.google.com/uc?export=view&id=1j-QoS5ik4P2SUiFLBwgZrZ3wEtpcVFI_\" style=\"width:50%\">\n",
    "<caption><center> Inception-C block. </center></caption>\n",
    "\n",
    "\n",
    "### Note\n",
    " - The average pooling has ``pool_size = (3, 3)`` and ``strides = (1, 1)``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZbH4KqkbCHzI"
   },
   "outputs": [],
   "source": [
    "# FUNCTION: Inception-C block\n",
    "\n",
    "def inception_c_block(X_input, base_name):\n",
    "    \"\"\"\n",
    "    Implementation of the Inception-C block\n",
    "\n",
    "    Arguments:\n",
    "    X_input -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
    "\n",
    "    Returns:\n",
    "    X -- output of the block, tensor of shape (n_H, n_W, n_C)\n",
    "    \"\"\"\n",
    "\n",
    "    ### START CODE HERE ###\n",
    "\n",
    "    # Branch 1\n",
    "    branch1 = None\n",
    "\n",
    "    # Branch 2\n",
    "    branch2 = None\n",
    "\n",
    "    # Branch 3\n",
    "    branch3 = None\n",
    "\n",
    "    # Branch 4\n",
    "    branch4 = None\n",
    "\n",
    "    # Concatenate branch1, branch2, branch3_1, branch3_2, branch4_1 and branch4_2 along the channel axis\n",
    "    X = None\n",
    "\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hLwqmDrLCHzI"
   },
   "outputs": [],
   "source": [
    "tf.random.set_seed(1)\n",
    "X_inp = tf.random.normal((4, 100, 100, 3), dtype=tf.dtypes.float32)\n",
    "\n",
    "X_out = inception_c_block(X_inp, 'c')\n",
    "print(\"shape output\" + str(X_out.shape))\n",
    "print(\"out = \" + str(X_out[:, 0, 0, 0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yx1qAxPXxWGC"
   },
   "source": [
    "Expected output:\n",
    "\n",
    "``shape output(4, 100, 100, 1536)``\n",
    "\n",
    "``out = tf.Tensor([0.04224635 0.1296405  0.0542384  0.        ], shape=(4,), dtype=float32)\n",
    "``\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g4SkLBiGCHzJ"
   },
   "source": [
    "### 1.6 - The Reduction-A block\n",
    "\n",
    "Implement below the Reduction-A block as detailed in the figure:\n",
    "\n",
    "<img src=\"https://drive.google.com/uc?export=view&id=1-1Ntm8Xw07GFkhpqV_TWLfA4MWnevXZS\" style=\"width:40%\">\n",
    "<caption><center> Reduction-A block. </center></caption>\n",
    "\n",
    "### Note\n",
    "For the Inception-v4 the parameters are as follows:\n",
    "- $n = 384$\n",
    "- $k = 192$\n",
    "- $l = 224$\n",
    "- $m = 256$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UMUHRz1QCHzJ"
   },
   "outputs": [],
   "source": [
    "# FUNCTION: Reduction-A block\n",
    "\n",
    "def reduction_a_block(X_input):\n",
    "    \"\"\"\n",
    "    Implementation of the Reduction-A block\n",
    "\n",
    "    Arguments:\n",
    "    X_input -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
    "\n",
    "    Returns:\n",
    "    X -- output of the block, tensor of shape (n_H, n_W, n_C)\n",
    "    \"\"\"\n",
    "\n",
    "    ### START CODE HERE ###\n",
    "\n",
    "    # Branch 1\n",
    "    branch1 = None\n",
    "\n",
    "    # Branch 2\n",
    "    branch2 = None\n",
    "\n",
    "    # Branch 3\n",
    "    branch3 = None\n",
    "\n",
    "    # Concatenate branch1, branch2 and branch3 along the channel axis\n",
    "    X = None\n",
    "\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yAQX95riCHzJ"
   },
   "outputs": [],
   "source": [
    "tf.random.set_seed(1)\n",
    "X_inp = tf.random.normal((4, 100, 100, 3), dtype=tf.dtypes.float32)\n",
    "\n",
    "X_out = reduction_a_block(X_inp)\n",
    "print(\"shape output\" + str(X_out.shape))\n",
    "print(\"out = \" + str(X_out[:, 0, 0, 0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YaiaDjbbxhvI"
   },
   "source": [
    "Expected output:\n",
    "\n",
    "``shape output(4, 49, 49, 643)``\n",
    "\n",
    "``out = tf.Tensor([1.3573772  0.54856557 1.4745578  0.3727632 ], shape=(4,), dtype=float32)\n",
    "``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jVEK5kS6CHzJ"
   },
   "source": [
    "### 1.7 - The Reduction-B block\n",
    "\n",
    "Implement below the Reduction-B block as detailed in the figure:\n",
    "\n",
    "<img src=\"https://drive.google.com/uc?export=view&id=1hnE2PP7O3CDBy91LIqB73yoyzfB-hX70\" style=\"width:40%\">\n",
    "<caption><center> Reduction-B block. </center></caption>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rmdenDXtCHzJ"
   },
   "outputs": [],
   "source": [
    "# FUNCTION: Reduction-B block\n",
    "\n",
    "def reduction_b_block(X_input):\n",
    "    \"\"\"\n",
    "    Implementation of the Reduction-B block\n",
    "\n",
    "    Arguments:\n",
    "    X_input -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
    "\n",
    "    Returns:\n",
    "    X -- output of the block, tensor of shape (n_H, n_W, n_C)\n",
    "    \"\"\"\n",
    "\n",
    "    ### START CODE HERE ###\n",
    "\n",
    "    # Branch 1\n",
    "    branch1 = None\n",
    "\n",
    "    # Branch 2\n",
    "    branch2 = None\n",
    "\n",
    "    # Branch 3\n",
    "    branch3 = None\n",
    "\n",
    "    # Concatenate branch1, branch2 and branch3 along the channel axis\n",
    "    X = None\n",
    "\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1tyiYBXQCHzJ"
   },
   "outputs": [],
   "source": [
    "tf.random.set_seed(1)\n",
    "X_inp = tf.random.normal((4, 100, 100, 3), dtype=tf.dtypes.float32)\n",
    "\n",
    "X_out = reduction_b_block(X_inp)\n",
    "print(\"shape output\" + str(X_out.shape))\n",
    "print(\"out = \" + str(X_out[:, 0, 0, 0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UfijgROUxlNf"
   },
   "source": [
    "Expected output:\n",
    "\n",
    "``shape output(4, 49, 49, 515)``\n",
    "\n",
    "``out = tf.Tensor([1.3573772  0.54856557 1.4745578  0.3727632 ], shape=(4,), dtype=float32)\n",
    "``\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HtIZB36lCHzJ"
   },
   "source": [
    "### 1.8 - Network construction\n",
    "\n",
    "You have now implemented all the necessary blocks to build the **Inception-v4** network!\n",
    "\n",
    "Refer to the above figure about the whole network and stack the blocks you implemented in the helper functions to build the Inception network.\n",
    "\n",
    "\n",
    "#### Note:\n",
    "\n",
    "- Add a ``Flatten`` layer after the last ``AveragePooling2D`` layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4UGMbAz-CHzJ"
   },
   "outputs": [],
   "source": [
    "# FUNCTION: Inception-v4\n",
    "\n",
    "def Inceptionv4(input_shape):\n",
    "    \"\"\"\n",
    "    Implementation of the Inception-v4 architecture\n",
    "\n",
    "    Arguments:\n",
    "    input_shape -- shape of the images of the dataset\n",
    "    classes -- integer, number of classes\n",
    "\n",
    "    Returns:\n",
    "    model -- a Model() instance in Keras\n",
    "    \"\"\"\n",
    "\n",
    "    ### START CODE HERE ###\n",
    "\n",
    "    # Define the input as a tensor with shape input_shape (1 line)\n",
    "    X_input = None\n",
    "\n",
    "    # Call the above functions for the stem, inception-a, reduction-a, inception-b, reduction-b and inception-c blocks\n",
    "    X = None\n",
    "\n",
    "    # Four Inception A blocks\n",
    "    X = None\n",
    "\n",
    "    # Reduction A block\n",
    "    X = reduction_a_block(X)\n",
    "\n",
    "    # Seven Inception B blocks\n",
    "    X = None\n",
    "\n",
    "    # Reduction B block\n",
    "    X = None\n",
    "\n",
    "    # Three Inception C blocks\n",
    "    X = None\n",
    "\n",
    "    # AVGPOOL (1 line). Use \"X = AveragePooling2D(...)(X)\"\n",
    "    kernel_pooling = (1,1) # you should check it in the model.summary() list of layers and dimensions\n",
    "    X = None\n",
    "\n",
    "    # Dropout\n",
    "    X = None\n",
    "\n",
    "    # Output layer\n",
    "    X = None\n",
    "\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    # Create model\n",
    "    model = Model(inputs = X_input, outputs = X, name='Inceptionv4')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-lgrU2G-CHzK"
   },
   "source": [
    "## 2 - Network training\n",
    "\n",
    "- Create the model, using the correct input shape for the dataset, and compile it.\n",
    "- Use `binary_crossentropy` for the loss as we need to solve a binary classification problem.\n",
    "- As optimizer try this time `SGD` using ``optimizer = tf.keras.optimizers.SGD()`` specifying ``learning rate = 0.005``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L3hvvob5CHzK"
   },
   "outputs": [],
   "source": [
    "model = None\n",
    "optimizer = None\n",
    "\n",
    "# Compile the model\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M5yCcwbgCHzK"
   },
   "source": [
    "Use the early stopping callback ([documentation here](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping)) to stop the training when the validation loss stops decreasing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DXmCaFn-CHzK"
   },
   "outputs": [],
   "source": [
    "# Create a callback for early stopping\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mQdbrzeu-PYL"
   },
   "source": [
    "In the next cell we create a callback for tensorboard that helps in model visualization and in analyzing the training process. See the details at [this link](https://colab.research.google.com/github/tensorflow/tensorboard/blob/master/docs/tensorboard_in_notebooks.ipynb#scrollTo=lpUO9HqUKP6z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g-JMm3tT-PCM"
   },
   "outputs": [],
   "source": [
    "# Create a callback for tensorboard\n",
    "%load_ext tensorboard\n",
    "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
    "!mkdir -p logs\n",
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dpHvPWB_CHzK"
   },
   "source": [
    "Fit the model on the data using real-time data augmentation. Use the method `flow` of `ImageDataGenerator` ([documentation here](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator#flow)). In addition to the training data, specify `validation_data`, `steps_per_epoch`, `validation_steps` and `callbacks` (see [here](https://www.tensorflow.org/api_docs/python/tf/keras/Model#fit))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 36,
     "status": "ok",
     "timestamp": 1763667680646,
     "user": {
      "displayName": "Eleonora Cicciarella",
      "userId": "16421968711967046601"
     },
     "user_tz": -60
    },
    "id": "KX0SWrSkCHzK"
   },
   "outputs": [],
   "source": [
    "# Fit the model on batches with real-time data augmentation:\n",
    "### START CODE HERE ###\n",
    "None\n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Iii4ADoyCHzK"
   },
   "outputs": [],
   "source": [
    "model.save('my_inception_model.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2QZE0LtmCHzK"
   },
   "source": [
    "## 3 - Performance assessment\n",
    "\n",
    "To load the pre-trained model and use it on the test set, uncomment the line in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zx1KaCkrCHzK"
   },
   "outputs": [],
   "source": [
    "# model = load_model('Inceptionv4.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "smO1zkHOCHzK"
   },
   "source": [
    "### 3.1 - Loss and accuracy\n",
    "Compute the loss and accuracy on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5iYGJZrFCHzL"
   },
   "outputs": [],
   "source": [
    "preds = model.evaluate(datagen_test.flow(x_test, y_test, batch_size=test_length, shuffle=False), steps=1)\n",
    "print('Loss = {:.5f}'.format(preds[0]))\n",
    "print('Test Accuracy = {:.2f}%'.format(preds[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z0SkS21nCHzL"
   },
   "source": [
    "### 3.2 - Precision, recall, fscore\n",
    "\n",
    "The performance of the neural network architecture can be evaluated with other metrics that provide additional information with respect to accuracy. Moreover, in the case of imbalanced datasets (i.e., when the elements in the dataset are not equally distributed among the classes), accuracy is not a good metric and others should be preferred.\n",
    "\n",
    "Here we consider three other metrics: **precision**, **recall** and **fscore**. You will use some methods from the *scikit-learn* library [documentation here](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics).\n",
    "\n",
    "First, we need the output of the network for all the validation samples. To obtain it use:\n",
    "```python\n",
    "model.predict(datagen_test.flow(x_test, batch_size=batch_size, shuffle=False), steps=test_steps)[:test_length].squeeze()\n",
    "```\n",
    "The ```[:test_length]``` is needed because the elements in ```[test_length:]``` are not part of our dataset, they are added to complete the batch.\n",
    "\n",
    "Then, if the output is < 0.5, the estimated class is `no tumor`, otherwise, pixels of tumor tissue have been detected in the image: use\n",
    "```python\n",
    "(test_values > 0.5).astype(int)\n",
    "```\n",
    "\n",
    "At this point, compute the precision, recall, fscore using the ``precision_recall_fscore_support`` function setting the parameter ``average='binary'`` ([here](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_recall_fscore_support.html#sklearn.metrics.precision_recall_fscore_support) the documentation). As we are not interested in the last output of this function we put an underscore to consider the position (without the placeholder, that line returns the error ```ValueError: too many values to unpack (expected 3)```)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KxF4t_4zCHzL"
   },
   "outputs": [],
   "source": [
    "### START CODE HERE ### (3 lines)\n",
    "# Get the network output for the validation set\n",
    "test_values = None\n",
    "\n",
    "# Get the estimated classes\n",
    "test_y_est = None\n",
    "\n",
    "# Compute precision, recall, fscore\n",
    "precision, recall, fscore, _= None\n",
    "### END CODE HERE ###\n",
    "\n",
    "print('Precision = {:.2f}%'.format(precision*100))\n",
    "print('Recall = {:.2f}%'.format(recall*100))\n",
    "print('Fscore = {:.2f}%'.format(fscore*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uv0IsCCfCHzL"
   },
   "source": [
    "### 3.3 - Receiver operating characteristic (ROC) curve\n",
    "\n",
    "Another interesting analysis is the evaluation of the ROC curve. The curve is obtained by evaluating the *False Positive Rate* (FPR) and the *True Positive Rate* (TPR) by varying the threshold used to infer the estimated classes (0.5 in the previous case).\n",
    "\n",
    "More specifically, in the previous case, we evaluated the metrics considering as positives all the examples with an output > 0.5. In this case, the output will be compared to many different thresholds, achieving a different performance for each one of them. The ROC is obtained by plotting the value of the TPR and FPR pair for the different thresholds.\n",
    "\n",
    "Fortunately, scikit.learn also exposes a function `roc_curve` for this purpose, see [here](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_curve.html) the documentation. You just need the network outputs (*val_preds*) and the corresponding labels (*val_labels*). Compute the area under the ROC curve using the `auc` function [here](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.auc.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "07Ms4vmpCHzL"
   },
   "outputs": [],
   "source": [
    "### START CODE HERE ### (2 lines)\n",
    "fpr, tpr, _ = None\n",
    "roc_auc = None\n",
    "### END CODE HERE ###\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic (ROC)')\n",
    "plt.legend(loc=\"lower right\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DJoTv4nOCHzL"
   },
   "source": [
    "### 3.4 - Precision-Recall Curve (PRC)\n",
    "We can do the exact same thing with precision and recall (instead of TPR and FPR), generating the precision-recall curve (PRC). Select the proper function from [here](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Dx2S7K_ECHzL"
   },
   "outputs": [],
   "source": [
    "### START CODE HERE ### (1 line)\n",
    "prec, rec, _ = None\n",
    "### END CODE HERE ###\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(prec, rec, color='darkorange', lw=2)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Precision')\n",
    "plt.ylabel('Recall')\n",
    "plt.title('Precision-Recall Curve (PRC)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f8oRwp9cCHzL"
   },
   "source": [
    "**Congratulations! Lab 3 completed :)**\n",
    "\n",
    "What can you do now?\n",
    "- This time we have not created an optimized input pipeline (there were already a lot of holes to fill...) but you can try to change the code and implement it as in Lab 2.\n",
    "- We used a subset of the complete dataset available [here](https://github.com/basveeling/pcam). You can try to increase the number of training images to evaluate the performance of the Inception v4 neural network.\n",
    "- For simplicity, we used only two sets, training, and test. Remember that in a real evaluation we need three sets: training, validation, and test. The validation set is used during training to select the best hyperparameters (number of layers, neurons per layer...) and the epoch where to stop training. The test set is used to assess the performance of the resulting network, and it is never used during training."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "coursera": {
   "course_slug": "convolutional-neural-networks",
   "graded_item_id": "OEpi5",
   "launcher_item_id": "jK9EQ"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
